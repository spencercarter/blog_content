{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A fast and dirty intro to running a model via web service\n",
    "\n",
    "Have you ever needed to score data with a predictive model in (near) real time, using a remote server/machine? While not a statistical or machine learning topic, it's one that I struggled with for a while, and haven't found many resources for.\n",
    "\n",
    "In this post, we're going to assume an understanding of predictive modeling and python, to focus on a simple way to set up a web service that can recieve data and return model predictions over the internet.\n",
    "\n",
    "This way is by no means definitive, but is straightforward and effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Part 3: Sender](http://spencercarter.info/docs/model_web_service_flask_3.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Home stretch! Now we just need a way to send data to our web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Repeat the setup block for the listener and sender\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LassoCV\n",
    "import pandas as pd\n",
    "from flask import Flask\n",
    "from flask import request\n",
    "import requests\n",
    "import pickle\n",
    "from time import time\n",
    "\n",
    "def unpickle_me(infile):\n",
    "    with open(infile, 'rb') as f:\n",
    "        unpickled = pickle.load(f)\n",
    "    return unpickled\n",
    "\n",
    "# Read in our pickled dictionary\n",
    "stored = unpickle_me('model_web_service.pickle')\n",
    "\n",
    "# Save the data types we  expect, to ensure typing works\n",
    "df_types = stored['dtypes']\n",
    "predictors = stored['predictors']\n",
    "X = stored['X']\n",
    "lasso = stored['lasso']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to generate some test cases from our data. As you saw when creating the scoring function, we're going to turn our data into a JSON. To make things a little simpler here, we're going to make a sender that takes a row number, and sends a JSON of the data to our webservice (which you should run in a separate notebook).\n",
    "\n",
    "Status code 200 indicates success, and all others indicate something failed. As a simple failsafe, we'll return 0.0 to signal a failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_a_post(indx):\n",
    "    url = \"http://127.0.0.1:1234/mass\"\n",
    "    data = X.iloc[indx].to_json()\n",
    "    req = requests.post(url, json=data)\n",
    "    if req.status_code != 200:\n",
    "        return .0\n",
    "    return float(req.content.decode(\"utf-8\")) # The prediction will come in as a byte. Decode, then make float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's toss obervation 0 to the webservice. We know from earlier, that it should return 30.505530469875787, rounded to 2 decimal-places. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.51"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_a_post(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a few more for show. Let's sample over the observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs 257: 41.79\n",
      "Obs 195: 37.82\n",
      "Obs 166: 37.75\n",
      "Obs 168: 26.51\n",
      "Obs 027: 16.4\n",
      "Obs 289: 26.16\n",
      "Obs 107: 20.25\n",
      "Obs 225: 38.77\n",
      "Obs 322: 23.24\n",
      "Obs 504: 26.59\n"
     ]
    }
   ],
   "source": [
    "for i in np.random.choice(range(X.shape[0]), 10):\n",
    "    print(\"Obs {0:03d}: {1}\".format(i, make_a_post(i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's see how long these take to run. Take the average of 100 runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over 100 runs, the web service averaged 0.0133 seconds to score\n"
     ]
    }
   ],
   "source": [
    "lag = []\n",
    "rep = 100\n",
    "for _ in range(100):\n",
    "    t0 = time()\n",
    "    make_a_post(0)\n",
    "    lag.append(time()-t0)\n",
    "print(\"Over {0} runs, the web service averaged {1:0.4f} seconds to score\".format(rep,np.mean(lag)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Success!**\n",
    "\n",
    "Sky's the limit here. This post focused only on cases where you might stream individual data. However, Flask can also receive files, allowing us to send a CSV containing multiple observations to score. This might be a topic for a future post.\n",
    "\n",
    "To learn more about flask, check out the <a href=\"http://flask.pocoo.org/\">Official Documentation</a> and the <a href=\"https://pythonprogramming.net/practical-flask-introduction/\">pythonprogramming.net tutorial</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base]",
   "language": "python",
   "name": "conda-env-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
